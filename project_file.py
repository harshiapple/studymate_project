# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hL-bkxbsRC0TSh9XwViNwATIlUxxCXY9
"""

!pip install -q transformers torch accelerate PyMuPDF huggingface_hub

from huggingface_hub import login

# Enter your HF token here (you can keep it secret in real use)
hf_token = "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"
login(token=hf_token)

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_name = "ibm-granite/granite-3.3-2b-instruct"
device = "cuda" if torch.cuda.is_available() else "cpu"

# Use torch.bfloat16 only if using A100/V100/modern GPU
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype=torch.bfloat16 if device == "cuda" else torch.float32
).to(device)

import fitz  # PyMuPDF

def extract_text_from_pdf(file_bytes):
    text = ""
    with fitz.open(stream=file_bytes, filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
    return text

def answer_query(question, context):
    prompt = f"Context: {context}\nQuestion: {question}\nAnswer:"
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(
        **inputs,
        max_new_tokens=256,
        do_sample=True,
        temperature=0.7,
        top_p=0.9,
        pad_token_id=tokenizer.eos_token_id,
    )
    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return answer.split("Answer:")[-1].strip()

from IPython.display import display
import ipywidgets as widgets

uploader = widgets.FileUpload(accept='.pdf', multiple=False)
display(widgets.Label("ğŸ“„ Upload a PDF file:"))
display(uploader)

if uploader.value:
    uploaded_file = list(uploader.value.values())[0]
    file_bytes = uploaded_file["content"]  # ğŸŸ¢ FIXED: get raw bytes
    text = extract_text_from_pdf(file_bytes)

    print("\nğŸ“– Preview (First 1000 characters):\n")
    print(text[:1000] + "..." if len(text) > 1000 else text)

    question = input("\nâ“ Enter your question:\n")
    print("\nğŸ§  Thinking...\n")
    answer = answer_query(question, text)
    print("\nâœ… Answer:")
    print(answer)
else:
    print("âš ï¸ Please upload a PDF file.")















